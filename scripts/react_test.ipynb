{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct logic test notebook\n",
    "\n",
    "Цей ноутбук допомагає швидко перевірити підтримку structured output у LLM\n",
    "та прогнати `react_loop_node` на простому прикладі.\n",
    "\n",
    "Перед запуском переконайтеся, що vLLM/OpenAI endpoint і Graphiti доступні\n",
    "та налаштовані через `config.settings` або змінні оточення."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T20:53:14.935789Z",
     "start_time": "2026-01-17T20:53:14.234528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import asyncio\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "repo_root = Path(\"../graphity_lapa\")\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from clients.llm_client import get_llm_client\n",
    "from agent.nodes.generate_solve_response import generate_solve_response_node\n",
    "from agent.state import create_initial_state"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T21:25:47.152763Z",
     "start_time": "2026-01-17T21:25:45.851891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Прогін react_loop_node\n",
    "state = create_initial_state(\n",
    "    message_uid=\"demo-1\",\n",
    "    message_text=\"Поясни, що таке ReAct агент простими словами\",\n",
    "    user_id=\"local_test\",\n",
    ")\n",
    "\n",
    "# Приклад додаткового контексту (якщо потрібно)\n",
    "state[\"retrieved_context\"] = [\n",
    "    {\n",
    "        \"source_msg_uid\": \"seed-1\",\n",
    "        \"content\": \"ReAct поєднує reasoning і acting, чергуючи думки та дії.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "result = await generate_solve_response_node(state)\n",
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error generating response: Connection error.\n",
      "Error in generate_solve_response: Connection error.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 394, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 78, in handle_async_request\n",
      "    stream = await self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 124, in _connect\n",
      "    stream = await self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpcore/_backends/auto.py\", line 31, in connect_tcp\n",
      "    return await self._backend.connect_tcp(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpcore/_backends/anyio.py\", line 113, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: All connection attempts failed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1532, in request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1629, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1730, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 393, in handle_async_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: All connection attempts failed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/agent/nodes/generate_solve_response.py\", line 81, in generate_solve_response_node\n",
      "    result: AgentResponseSchema = await llm_client.generate_async(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/clients/llm_client.py\", line 108, in generate_async\n",
      "    response = await llm.ainvoke(lc_messages)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 3191, in ainvoke\n",
      "    input_ = await coro_with_context(part(), context, create_task=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 5570, in ainvoke\n",
      "    return await self.bound.ainvoke(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 425, in ainvoke\n",
      "    llm_result = await self.agenerate_prompt(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1132, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1090, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1359, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 1634, in _agenerate\n",
      "    raise e\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 1597, in _agenerate\n",
      "    raw_response = await self.root_async_client.chat.completions.with_raw_response.parse(  # noqa: E501\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/openai/_legacy_response.py\", line 381, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1670, in parse\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1797, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/creator/Documents/Creator/PythonProject/graphity_lapa/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1564, in request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'Вибачте, сталася технічна помилка при обробці запиту.', 'references': [], 'reasoning': 'Exception: Connection error.'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
