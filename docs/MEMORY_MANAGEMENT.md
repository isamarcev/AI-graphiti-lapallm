# –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ Memory Management

> –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è —Å–∏—Å—Ç–µ–º–∏ —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è –ø–∞–º'—è—Ç—Ç—é –≤ Tabula Rasa Agent
> –í–µ—Ä—Å—ñ—è: 2.0 (–ø—ñ—Å–ª—è —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É –Ω–∞ teach/solve architecture)

## –ó–º—ñ—Å—Ç

- [–û–≥–ª—è–¥ —Å–∏—Å—Ç–µ–º–∏](#–æ–≥–ª—è–¥-—Å–∏—Å—Ç–µ–º–∏)
- [–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –ø–∞–º'—è—Ç—ñ](#–∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞-–ø–∞–º—è—Ç—ñ)
- [–ü–æ—Ç–æ–∫–∏ –¥–∞–Ω–∏—Ö](#–ø–æ—Ç–æ–∫–∏-–¥–∞–Ω–∏—Ö)
- [–û–ø–µ—Ä–∞—Ü—ñ—ó –∑ –ø–∞–º'—è—Ç—Ç—é](#–æ–ø–µ—Ä–∞—Ü—ñ—ó-–∑-–ø–∞–º—è—Ç—Ç—é)
- [–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —Ç–∞ –ø—Ä–æ–±–ª–µ–º–∏](#–æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è-—Ç–∞-–ø—Ä–æ–±–ª–µ–º–∏)

---

## –û–≥–ª—è–¥ —Å–∏—Å—Ç–µ–º–∏

### –î–≤–æ—à–∞—Ä–æ–≤–∞ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

–°–∏—Å—Ç–µ–º–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î **–¥–≤–∞ –Ω–µ–∑–∞–ª–µ–∂–Ω—ñ —à–∞—Ä–∏** –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 1: Graphiti (Temporal Knowledge Graph)          ‚îÇ
‚îÇ  - Entities (—Å—É—Ç–Ω–æ—Å—Ç—ñ)                                  ‚îÇ
‚îÇ  - Relations (–∑–≤'—è–∑–∫–∏ –º—ñ–∂ —Å—É—Ç–Ω–æ—Å—Ç—è–º–∏)                   ‚îÇ
‚îÇ  - Episodes (conversation turns)                        ‚îÇ
‚îÇ  - Temporal reasoning (–∑–º—ñ–Ω–∏ –≤ —á–∞—Å—ñ)                    ‚îÇ
‚îÇ  ‚Üí –î–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ–≥–æ –ø–æ—à—É–∫—É —Ç–∞ reasoning                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚îÇ –ü–æ–≤'—è–∑–∞–Ω—ñ —á–µ—Ä–µ–∑ episode_name
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 2: Neo4j Message Store (Reference Tracking)     ‚îÇ
‚îÇ  - Message nodes (–∑ UIDs)                               ‚îÇ
‚îÇ  - Episode nodes (links)                                ‚îÇ
‚îÇ  - Timestamps, user IDs                                 ‚îÇ
‚îÇ  ‚Üí –î–ª—è source references –≤ –≤—ñ–¥–ø–æ–≤—ñ–¥—è—Ö                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### –ß–æ–º—É –¥–≤–∞ —à–∞—Ä–∏?

**Graphiti** (Layer 1):
- –ó–±–µ—Ä—ñ–≥–∞—î **—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ –∑–Ω–∞–Ω–Ω—è** (entities + relations)
- –í–∏–∫–æ–Ω—É—î **hybrid search** (semantic + BM25)
- –ü—ñ–¥—Ç—Ä–∏–º—É—î **temporal reasoning** (–∑–º—ñ–Ω–∏ —Ñ–∞–∫—Ç—ñ–≤ –≤ —á–∞—Å—ñ)
- LLM –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏—Ç—è–≥—É—î entities –∑ episodes

**Neo4j Message Store** (Layer 2):
- –ó–±–µ—Ä—ñ–≥–∞—î **raw messages** –∑ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–º–∏ UIDs
- –î–æ–∑–≤–æ–ª—è—î **track–∞—Ç–∏ –¥–∂–µ—Ä–µ–ª–∞** (source references)
- –®–≤–∏–¥–∫–∏–π lookup: episode_name ‚Üí message_uid
- Needed –¥–ª—è –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π –∑ –ø–æ—Å–∏–ª–∞–Ω–Ω—è–º–∏ –Ω–∞ –¥–∂–µ—Ä–µ–ª–∞

---

## –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –ø–∞–º'—è—Ç—ñ

### –¢–∏–ø–∏ –ø–∞–º'—è—Ç—ñ –≤ —Å–∏—Å—Ç–µ–º—ñ

–°–∏—Å—Ç–µ–º–∞ —ñ–º–ø–ª–µ–º–µ–Ω—Ç—É—î **3 —Ç–∏–ø–∏ –ø–∞–º'—è—Ç—ñ** –∑ research paper:

#### 1. Semantic Memory (–°–µ–º–∞–Ω—Ç–∏—á–Ω–∞ –ø–∞–º'—è—Ç—å)

**–©–æ –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è:** –§–∞–∫—Ç–∏, –∑–Ω–∞–Ω–Ω—è, —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ

**–î–µ:** Graphiti ‚Üí Entity/Relation nodes

**–ü—Ä–∏–∫–ª–∞–¥:**
```
Episode: "–ö–∏—ó–≤ - —Å—Ç–æ–ª–∏—Ü—è –£–∫—Ä–∞—ó–Ω–∏"
   ‚Üì LLM extraction
Entity(name="–ö–∏—ó–≤", type="CITY")
Entity(name="–£–∫—Ä–∞—ó–Ω–∞", type="COUNTRY")
Relation(–ö–∏—ó–≤ ‚Üí —Å—Ç–æ–ª–∏—Ü—è ‚Üí –£–∫—Ä–∞—ó–Ω–∞)
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- Retrieve context node —à—É–∫–∞—î —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ entities
- Hybrid search (embeddings + BM25)
- Reranking –∑ BGE cross-encoder

#### 2. Episodic Memory (–ï–ø—ñ–∑–æ–¥–∏—á–Ω–∞ –ø–∞–º'—è—Ç—å)

**–©–æ –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è:** Conversation turns (user + assistant pairs)

**–î–µ:**
- Graphiti ‚Üí Episode nodes (–∑ timestamps)
- Neo4j ‚Üí Message nodes (–∑ UIDs)

**–ü—Ä–∏–∫–ª–∞–¥:**
```
Episode {
  name: "teach_msg-001",
  body: "User: –ö–∏—ó–≤ - —Å—Ç–æ–ª–∏—Ü—è –£–∫—Ä–∞—ó–Ω–∏\nAssistant: –î—è–∫—É—é –∑–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é...",
  timestamp: 2024-01-15T10:30:00Z
}
   ‚Üì
Message {
  uid: "msg-001",
  text: "–ö–∏—ó–≤ - —Å—Ç–æ–ª–∏—Ü—è –£–∫—Ä–∞—ó–Ω–∏",
  episode_name: "teach_msg-001"
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- –ö–æ–∂–µ–Ω conversation turn = –æ–∫—Ä–µ–º–∏–π episode
- Temporal queries (–∫–æ–ª–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á —â–æ—Å—å —Å–∫–∞–∑–∞–≤)
- Source references —á–µ—Ä–µ–∑ episode_name ‚Üí message_uid lookup

#### 3. Procedural Memory (–ü—Ä–æ—Ü–µ–¥—É—Ä–Ω–∞ –ø–∞–º'—è—Ç—å)

**–©–æ –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è:** –Ø–∫ –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏ –∑–∞–¥–∞—á—ñ (implicitly –≤ ReAct steps)

**–î–µ:** –ù–µ –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è —è–≤–Ω–æ (–Ω–∞ –≤—ñ–¥–º—ñ–Ω—É –≤—ñ–¥ semantic/episodic)

**–Ø–∫ –ø—Ä–∞—Ü—é—î:**
- ReAct loop –≤—á–∏—Ç—å—Å—è patterns –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö successful iterations
- Reasoning steps (thought ‚Üí action ‚Üí observation)
- –ù–µ–º–∞—î explicit storage, —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É—é—î—Ç—å—Å—è –∑ episodic memory

**–ü—Ä–∏–∫–ª–∞–¥:**
```
–ó–∞–≤–¥–∞–Ω–Ω—è: "–°—Ç–≤–æ—Ä–∏ —Ä–µ—Ü–µ–ø—Ç —Å–∞–ª–∞—Ç—É"
   ‚Üì ReAct learns pattern
Thought: "–®—É–∫–∞—é —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç–∏ –∑ –ø–∞–º'—è—Ç—ñ"
Action: search
Observation: "–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á —Ä–∞–Ω—ñ—à–µ –∫–∞–∑–∞–≤ —â–æ –ª—é–±–∏—Ç—å –ø–æ–º—ñ–¥–æ—Ä–∏"
   ‚Üì
Thought: "–ú–æ–∂—É —Å—Ç–≤–æ—Ä–∏—Ç–∏ —Å–∞–ª–∞—Ç –∑ –ø–æ–º—ñ–¥–æ—Ä—ñ–≤"
Action: answer
```

---

## –ü–æ—Ç–æ–∫–∏ –¥–∞–Ω–∏—Ö

### TEACH Path (User ‚Üí Agent)

–ö–æ–ª–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á **–Ω–∞–¥–∞—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é** (teaching):

```
1. classify_intent_node
   ‚Üì intent="teach"

2. extract_facts_node
   ‚Üì LLM –≤–∏—Ç—è–≥—É—î —Ñ–∞–∫—Ç–∏
   [{subject: "–ö–∏—ó–≤", relation: "—Å—Ç–æ–ª–∏—Ü—è", object: "–£–∫—Ä–∞—ó–Ω–∞"}]

3. check_conflicts_node
   ‚Üì –ü–µ—Ä–µ–≤—ñ—Ä—è—î –∫–æ–Ω—Ñ–ª—ñ–∫—Ç–∏ –∑ —ñ—Å–Ω—É—é—á–∏–º–∏ —Ñ–∞–∫—Ç–∞–º–∏
   –®—É–∫–∞—î –≤ Graphiti: search("–ö–∏—ó–≤ —Å—Ç–æ–ª–∏—Ü—è")

4a. –Ø–∫—â–æ conflicts ‚Üí auto_resolve_node
    ‚îî‚îÄ Auto-accept –Ω–æ–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é (Tabula Rasa –ø—Ä–∏–Ω—Ü–∏–ø)

4b. –Ø–∫—â–æ NO conflicts ‚Üí generate_confirmation_node
    ‚îî‚îÄ LLM –≥–µ–Ω–µ—Ä—É—î –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è –Ω–∞–≤—á–∞–Ω–Ω—è

5. store_knowledge_node
   ‚îú‚îÄ Graphiti.add_episode() ‚Üí Entity/Relation extraction
   ‚îî‚îÄ Neo4j.save_message() ‚Üí Message node –∑ UID

   Episode: "teach_msg-001"
      ‚îú‚îÄ Graphiti: Episode(body, entities, relations, timestamp)
      ‚îî‚îÄ Neo4j: Message(uid, text, episode_name="teach_msg-001")
```

**–ö–æ–ª–∏ –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –ø–∞–º'—è—Ç—å:** –ó–∞–≤–∂–¥–∏ –≤ –∫—ñ–Ω—Ü—ñ TEACH path (store_knowledge_node)

**–©–æ —Å–∞–º–µ –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è:**
- Graphiti: Episode ‚Üí LLM –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏—Ç—è–≥—É—î entities/relations
- Neo4j: Raw message –∑ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–º UID

### SOLVE Path (Agent ‚Üí User)

–ö–æ–ª–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á **—Å—Ç–∞–≤–∏—Ç—å –∑–∞–≤–¥–∞–Ω–Ω—è** (asking):

```
1. classify_intent_node
   ‚Üì intent="solve"

2. retrieve_context_node
   ‚îú‚îÄ Graphiti.search(query) ‚Üí Hybrid search (semantic + BM25)
   ‚îî‚îÄ Results: [{content, episode_name, score, timestamp}]

3. –î–ª—è –∫–æ–∂–Ω–æ–≥–æ result:
   ‚îú‚îÄ episode_name ‚Üí Neo4j.get_message_uid_by_episode()
   ‚îî‚îÄ –î–æ–¥–∞—î–º–æ source_msg_uid –¥–æ context

4. react_loop_node
   ‚îú‚îÄ Iterative reasoning (–¥–æ 3 iterations)
   ‚îú‚îÄ Thought: "–©–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑—Ä–æ–±–∏—Ç–∏?"
   ‚îú‚îÄ Action: "search" –∞–±–æ "answer"
   ‚îî‚îÄ Observation: —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ action

5. generate_answer_node
   ‚îú‚îÄ LLM –≥–µ–Ω–µ—Ä—É—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑ context
   ‚îú‚îÄ Extract message UIDs –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏—Ö sources
   ‚îî‚îÄ Response + references
```

**–ö–æ–ª–∏ –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –ø–∞–º'—è—Ç—å:** **–ù–Ü!** SOLVE path –ù–ï –∑–±–µ—Ä—ñ–≥–∞—î –Ω–æ–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é

**–ß–æ–º—É –Ω–µ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ:**
- SOLVE = retrieval + reasoning + generation
- –ù–µ —Å—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤—ñ —Ñ–∞–∫—Ç–∏, –ª–∏—à–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ñ—Å–Ω—É—é—á—ñ
- –£–Ω–∏–∫–∞—î–º–æ –¥—É–±–ª—é–≤–∞–Ω–Ω—è (–Ω–µ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ generated –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —è–∫ facts)

---

## –û–ø–µ—Ä–∞—Ü—ñ—ó –∑ –ø–∞–º'—è—Ç—Ç—é

### 1. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è (TEACH path only)

#### store_knowledge_node (agent/nodes/store.py:19)

```python
async def store_knowledge_node(state: AgentState):
    # 1. Add episode to Graphiti
    episode_name = f"teach_{state['message_uid']}"

    episode_body = f"""User: {user_message}
Assistant: {assistant_message}"""

    await graphiti.add_episode(
        episode_body=episode_body,
        episode_name=episode_name,
        source_description=f"user:{user_id}, uid:{message_uid}",
        reference_time=timestamp  # Temporal reasoning
    )

    # 2. Save to Neo4j for references
    await message_store.save_message(
        uid=message_uid,
        text=user_message,
        episode_name=episode_name,
        user_id=user_id,
        timestamp=timestamp
    )
```

**–ö–æ–ª–∏ –≤–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è:**
- –í –∫—ñ–Ω—Ü—ñ TEACH path
- –ü—ñ—Å–ª—è conflict resolution (—è–∫—â–æ –±—É–ª–∏ –∫–æ–Ω—Ñ–ª—ñ–∫—Ç–∏)
- –ü—ñ—Å–ª—è generate_confirmation (—è–∫—â–æ –Ω–µ –±—É–ª–æ –∫–æ–Ω—Ñ–ª—ñ–∫—Ç—ñ–≤)

**–©–æ –≤—ñ–¥–±—É–≤–∞—î—Ç—å—Å—è –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ Graphiti:**
```
1. Episode –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –≤ Neo4j
2. LLM (Lapa) —á–∏—Ç–∞—î episode_body
3. –í–∏—Ç—è–≥—É—î entities: {name, type, summary}
4. –í–∏—Ç—è–≥—É—î relations: {source, target, type}
5. –°—Ç–≤–æ—Ä—é—î nodes –≤ Neo4j:
   - Episode node
   - Entity nodes (—è–∫—â–æ –Ω–æ–≤—ñ)
   - Relation edges –º—ñ–∂ entities
6. Embeddings –¥–ª—è entities (HostedQwenEmbedder)
7. BGE reranking metadata
```

### 2. –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è (SOLVE path)

#### retrieve_context_node (agent/nodes/retrieve.py:18)

```python
async def retrieve_context_node(state: AgentState):
    # Hybrid search –≤ Graphiti
    search_results = await graphiti.search(
        query=state["message_text"],
        limit=settings.graphiti_search_limit  # Default: 10
    )

    # –î–æ–¥–∞—î–º–æ source message UIDs
    retrieved_context = []
    for result in search_results:
        episode_name = result.get('episode_name')
        source_msg_uid = await get_message_uid_by_episode(episode_name)

        retrieved_context.append({
            "content": result['content'],
            "source_msg_uid": source_msg_uid,
            "timestamp": result['timestamp'],
            "score": result['score']
        })

    return {"retrieved_context": retrieved_context}
```

**Graphiti Hybrid Search:**
```
1. Semantic search (Qwen embeddings):
   - Embed query
   - Cosine similarity –∑ entity embeddings
   - Top-K results

2. BM25 (keyword-based):
   - Tokenize query
   - TF-IDF scoring
   - Top-K results

3. Merge + Rerank:
   - Combine semantic + BM25 results
   - BGE cross-encoder reranking
   - Sort by final score
```

**–ö–æ–ª–∏ –≤–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è:**
- –ù–∞ –ø–æ—á–∞—Ç–∫—É SOLVE path (–ø—ñ—Å–ª—è classify)
- –ü–µ—Ä–µ–¥ ReAct loop

**–§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è:**
- `relevance_threshold` = 0.3 (default)
- Skip empty results (len < 5 chars)
- Limit: 10 results

### 3. ReAct Additional Search

#### react_loop_node (agent/nodes/react.py:20)

```python
async def react_loop_node(state: AgentState):
    for iteration in range(max_iterations):  # –î–æ 3 iterations
        # 1. Thought
        thought = await llm.generate_async(thought_prompt)

        # 2. Action
        if "—à—É–∫–∞—Ç–∏" in thought.lower():
            action = "search"
            search_query = extract_search_query(thought)

            # –î–æ–¥–∞—Ç–∫–æ–≤–∏–π –ø–æ—à—É–∫ –≤ Graphiti
            search_results = await graphiti.search(
                query=search_query,
                limit=3  # –ú–µ–Ω—à–µ –Ω—ñ–∂ initial retrieve
            )

            # –î–æ–¥–∞—î–º–æ results –¥–æ context
            for result in search_results:
                context_text += f"\n{result['content']}"

        elif "–≥–æ—Ç–æ–≤–∏–π" in thought.lower():
            action = "answer"
            break
```

**–ß–æ–º—É –¥–æ–¥–∞—Ç–∫–æ–≤–∏–π search?**
- Initial retrieve –º–æ–∂–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ –¥–µ—Ç–∞–ª—ñ
- ReAct iterative refines –ø–æ—à—É–∫
- Smaller limit (3 vs 10) –¥–ª—è —Ñ–æ–∫—É—Å—É

**–ß–∏ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ ReAct steps?**
- **–ù–Ü!** –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –≤ state –¥–ª—è –ø–æ—Ç–æ—á–Ω–æ–≥–æ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
- –ù–µ —Å—Ç–≤–æ—Ä—é—î–º–æ episodes –∑ ReAct reasoning
- Reasoning —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É—é—î—Ç—å—Å—è –∫–æ–∂–µ–Ω —Ä–∞–∑ –∑–∞–Ω–æ–≤–æ

---

## –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —Ç–∞ –ø—Ä–æ–±–ª–µ–º–∏

### –ß–∏ —î –¥—É–±–ª—é–≤–∞–Ω–Ω—è –æ–ø–µ—Ä–∞—Ü—ñ–π?

#### ‚úÖ –ü—Ä–æ–±–ª–µ–º–∞: OLD architecture (nodes.py)

**–°—Ç–∞—Ä–∏–π –∫–æ–¥** (retrieve_memory_node + save_to_memory_node):
```python
# –ü–†–û–ë–õ–ï–ú–ê: –ó–±–µ—Ä—ñ–≥–∞–ª–∏ –ö–û–ñ–ù–£ interaction (teach + solve)
async def save_to_memory_node(state):
    # –ó–±–µ—Ä—ñ–≥–∞–ª–∏ –Ω–∞–≤—ñ—Ç—å SOLVE –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —è–∫ episodes
    episode_body = f"User: {user_msg}\nAssistant: {ai_msg}"
    await graphiti.add_episode(episode_body, ...)
```

**–©–æ –±—É–ª–æ –Ω–µ —Ç–∞–∫:**
1. SOLVE path —Å—Ç–≤–æ—Ä—é–≤–∞–≤ episodes –∑ generated –≤—ñ–¥–ø–æ–≤—ñ–¥—è–º–∏
2. LLM –≤–∏—Ç—è–≥—É–≤–∞–≤ "fake facts" –∑ AI responses
3. Graph –∑–∞–±—Ä—É–¥–Ω—é–≤–∞–≤—Å—è non-factual information
4. Retrieval –ø–æ–≤–µ—Ä—Ç–∞–≤ –≤–ª–∞—Å–Ω—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –∞–≥–µ–Ω—Ç–∞ —è–∫ "knowledge"

#### ‚úÖ –†—ñ—à–µ–Ω–Ω—è: NEW architecture (teach/solve split)

**–ù–æ–≤–∏–π –∫–æ–¥** (TEACH path only storage):
```python
# –¢–Ü–õ–¨–ö–ò TEACH path –∑–±–µ—Ä—ñ–≥–∞—î knowledge
workflow.add_edge("store_knowledge", END)  # TEACH
workflow.add_edge("generate_answer", END)  # SOLVE (no storage!)
```

**–ü–µ—Ä–µ–≤–∞–≥–∏:**
1. –ß—ñ—Ç–∫–µ —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è: teach = store, solve = retrieve
2. Graph –º—ñ—Å—Ç–∏—Ç—å —Ç—ñ–ª—å–∫–∏ user-provided facts
3. –ù–µ–º–∞—î self-pollution –≤—ñ–¥ AI responses
4. Episodic memory = —Ç—ñ–ª—å–∫–∏ teaching moments

### –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤–∏—Ç—è–≥–Ω—É—Ç–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É

#### retrieve_context_node ‚Üí generate_answer_node

```python
# retrieve_context_node
return {"retrieved_context": [
    {
        "content": "–ö–∏—ó–≤ - —Å—Ç–æ–ª–∏—Ü—è –£–∫—Ä–∞—ó–Ω–∏",
        "source_msg_uid": "msg-001",
        "score": 0.95
    }
]}

# react_loop_node
context_text = "\n".join([
    f"[{i}] ({ctx['source_msg_uid']}): {ctx['content']}"
    for i, ctx in enumerate(retrieved_context)
])

# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –≤ prompt
thought_prompt = f"""
–ö–æ–Ω—Ç–µ–∫—Å—Ç –∑ –ø–∞–º'—è—Ç—ñ:
{context_text}

–ó–∞–≤–¥–∞–Ω–Ω—è: {task}
"""

# generate_answer_node
system_prompt = f"""
üö´ TABULA RASA: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É.

=== –ö–æ–Ω—Ç–µ–∫—Å—Ç –∑ –ø–∞–º'—è—Ç—ñ ===
{format_context(retrieved_context)}
=== –ö—ñ–Ω–µ—Ü—å –∫–æ–Ω—Ç–µ–∫—Å—Ç—É ===

–ó–∞–≤–¥–∞–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞: {state['message_text']}
"""
```

**–Ø–∫ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è:**
1. Initial retrieve ‚Üí Base context –¥–ª—è ReAct
2. ReAct iterative search ‚Üí –î–æ–¥–∞—î –¥–æ context
3. Generate answer ‚Üí –í–µ—Å—å accumulated context –≤ prompt
4. Extract references ‚Üí Message UIDs –≤ response

### Redundancy Check

#### –ß–∏ —î –∑–∞–π–≤—ñ memory operations?

**TEACH path:**
```
‚úÖ extract_facts_node - –ù–ï –∑–±–µ—Ä—ñ–≥–∞—î, —Ç—ñ–ª—å–∫–∏ –≤–∏—Ç—è–≥—É—î
‚úÖ check_conflicts_node - –ù–ï –∑–±–µ—Ä—ñ–≥–∞—î, —Ç—ñ–ª—å–∫–∏ search –¥–ª—è comparison
‚úÖ auto_resolve_node - –ù–ï –∑–±–µ—Ä—ñ–≥–∞—î, —Ç—ñ–ª—å–∫–∏ decision logic
‚úÖ store_knowledge_node - –Ñ–î–ò–ù–ï –º—ñ—Å—Ü–µ –¥–µ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ
```

**SOLVE path:**
```
‚úÖ retrieve_context_node - –û–¥–∏–Ω —Ä–∞–∑ –Ω–∞ –ø–æ—á–∞—Ç–∫—É (broad search)
‚úÖ react_loop_node - –î–æ 3 –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö searches (focused queries)
‚úÖ generate_answer_node - NO storage, —Ç—ñ–ª—å–∫–∏ generation
```

**–í–∏—Å–Ω–æ–≤–æ–∫:** –ù–µ–º–∞—î –¥—É–±–ª—é–≤–∞–Ω–Ω—è. –ö–æ–∂–Ω–∞ –æ–ø–µ—Ä–∞—Ü—ñ—è –º–∞—î —á—ñ—Ç–∫–∏–π purpose.

---

## –î—ñ–∞–≥—Ä–∞–º–∞ –ø–æ–≤–Ω–æ–≥–æ flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    USER INPUT MESSAGE                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  classify_intent     ‚îÇ
              ‚îÇ  (LLM classification)‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ        ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ TEACH                    SOLVE ‚îÇ
         ‚ñº                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ extract_facts    ‚îÇ            ‚îÇ retrieve_context ‚îÇ
‚îÇ (LLM structured) ‚îÇ            ‚îÇ (Graphiti search)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                                ‚îÇ
         ‚ñº                                ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îÇ
‚îÇ check_conflicts  ‚îÇ                      ‚îÇ
‚îÇ (search + LLM)   ‚îÇ                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ
     ‚îÇ        ‚îÇ                           ‚îÇ
  conflict  no conflict                   ‚îÇ
     ‚îÇ        ‚îÇ                           ‚îÇ
     ‚ñº        ‚ñº                           ‚ñº
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇauto‚îÇ   ‚îÇconf-‚îÇ              ‚îÇ   react_loop     ‚îÇ
 ‚îÇres ‚îÇ   ‚îÇ irm ‚îÇ              ‚îÇ (iterative reas.)‚îÇ
 ‚îî‚îÄ‚î¨‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ         ‚îÇ                          ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
        ‚îÇ                               ‚îÇ
        ‚ñº                               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ store_knowledge  ‚îÇ            ‚îÇ generate_answer  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§            ‚îÇ (NO STORAGE!)    ‚îÇ
‚îÇ 1. Graphiti      ‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ    add_episode   ‚îÇ                     ‚îÇ
‚îÇ    ‚Üí entities    ‚îÇ                     ‚îÇ
‚îÇ    ‚Üí relations   ‚îÇ                     ‚îÇ
‚îÇ 2. Neo4j         ‚îÇ                     ‚îÇ
‚îÇ    save_message  ‚îÇ                     ‚îÇ
‚îÇ    ‚Üí UID link    ‚îÇ                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
         ‚îÇ                               ‚îÇ
         ‚ñº                               ‚ñº
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ          RESPONSE               ‚îÇ
       ‚îÇ  TEACH: confirmation            ‚îÇ
       ‚îÇ  SOLVE: answer + references     ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è

### –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è (config/settings.py)

```python
# Graphiti settings
graphiti_search_limit: int = 10           # Max results from search
graphiti_relevance_threshold: float = 0.3  # Min score to include
graphiti_max_episode_length: int = 2048   # Max tokens per episode

# ReAct settings
max_react_iterations: int = 3             # Max ReAct loop iterations

# Embeddings
embedding_model_name: str = "paraphrase-multilingual-mpnet-base-v2"
use_hosted_embeddings: bool = True        # HostedQwenEmbedder

# Neo4j
neo4j_uri: str = "bolt://localhost:7687"
neo4j_database: str = "neo4j"
```

### –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Graphiti Search

**Hybrid search balance:**
- Semantic weight: 0.7 (embeddings similarity)
- BM25 weight: 0.3 (keyword matching)
- Reranking: BGE cross-encoder (final scoring)

**Threshold explanation:**
- `relevance_threshold = 0.3` = –¥–æ—Å–∏—Ç—å liberal (–≤–∫–ª—é—á–∞—î–º–æ –±–∞–≥–∞—Ç–æ results)
- Scores 0.0-1.0 (1.0 = perfect match)
- –ù–∏–∂—á–µ 0.3 = likely irrelevant

---

## –ü—Ä–∏–∫–ª–∞–¥ end-to-end

### Scenario 1: TEACH ‚Üí SOLVE

```python
# 1. User teaches fact
>>> "–ö–∏—ó–≤ - —Å—Ç–æ–ª–∏—Ü—è –£–∫—Ä–∞—ó–Ω–∏"

# TEACH path:
classify ‚Üí intent="teach"
extract_facts ‚Üí [{subject: "–ö–∏—ó–≤", relation: "—Å—Ç–æ–ª–∏—Ü—è", object: "–£–∫—Ä–∞—ó–Ω–∞"}]
check_conflicts ‚Üí search("–ö–∏—ó–≤ —Å—Ç–æ–ª–∏—Ü—è") ‚Üí no conflicts
generate_confirmation ‚Üí "–î—è–∫—É—é, —è –∑–∞–ø–∞–º'—è—Ç–∞–≤ —â–æ –ö–∏—ó–≤ - —Å—Ç–æ–ª–∏—Ü—è –£–∫—Ä–∞—ó–Ω–∏"
store_knowledge:
  ‚îú‚îÄ Graphiti: Episode("teach_msg-001", body="User: –ö–∏—ó–≤...")
  ‚îÇ   ‚îî‚îÄ Entities: –ö–∏—ó–≤(CITY), –£–∫—Ä–∞—ó–Ω–∞(COUNTRY)
  ‚îÇ   ‚îî‚îÄ Relation: –ö–∏—ó–≤ -[—Å—Ç–æ–ª–∏—Ü—è]-> –£–∫—Ä–∞—ó–Ω–∞
  ‚îî‚îÄ Neo4j: Message(uid="msg-001", episode_name="teach_msg-001")

# 2. User asks question
>>> "–Ø–∫–∞ —Å—Ç–æ–ª–∏—Ü—è –£–∫—Ä–∞—ó–Ω–∏?"

# SOLVE path:
classify ‚Üí intent="solve"
retrieve_context:
  ‚îú‚îÄ Graphiti.search("–Ø–∫–∞ —Å—Ç–æ–ª–∏—Ü—è –£–∫—Ä–∞—ó–Ω–∏?")
  ‚îî‚îÄ Results: [{content: "–ö–∏—ó–≤ - —Å—Ç–æ–ª–∏—Ü—è –£–∫—Ä–∞—ó–Ω–∏", episode_name: "teach_msg-001", score: 0.95}]

  # Get source UID
  ‚îú‚îÄ Neo4j.get_message_uid_by_episode("teach_msg-001") ‚Üí "msg-001"
  ‚îî‚îÄ Add to context: {content: "...", source_msg_uid: "msg-001"}

react_loop (iteration 1):
  thought: "–í –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ —î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ —Å—Ç–æ–ª–∏—Ü—é –£–∫—Ä–∞—ó–Ω–∏ - —Ü–µ –ö–∏—ó–≤. –ì–æ—Ç–æ–≤–∏–π –≤—ñ–¥–ø–æ–≤—ñ—Å—Ç–∏."
  action: "answer"

generate_answer:
  ‚îú‚îÄ System prompt –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º: "[msg-001]: –ö–∏—ó–≤ - —Å—Ç–æ–ª–∏—Ü—è –£–∫—Ä–∞—ó–Ω–∏"
  ‚îú‚îÄ LLM generates: "–°—Ç–æ–ª–∏—Ü—è –£–∫—Ä–∞—ó–Ω–∏ - –ö–∏—ó–≤ [msg-001]"
  ‚îî‚îÄ Extract references: ["msg-001"]

Response:
  response: "–°—Ç–æ–ª–∏—Ü—è –£–∫—Ä–∞—ó–Ω–∏ - –ö–∏—ó–≤ [msg-001]"
  references: ["msg-001"]
```

### Scenario 2: Conflict resolution

```python
# 1. Initial fact
>>> "–ú–æ—î —É–ª—é–±–ª–µ–Ω–µ –º—ñ—Å—Ç–æ - –•–∞—Ä–∫—ñ–≤"
# TEACH ‚Üí stored as msg-001

# 2. Conflicting fact
>>> "–ú–æ—î —É–ª—é–±–ª–µ–Ω–µ –º—ñ—Å—Ç–æ - –õ—å–≤—ñ–≤"

# TEACH path:
classify ‚Üí intent="teach"
extract_facts ‚Üí [{subject: "—è", relation: "—É–ª—é–±–ª–µ–Ω–µ –º—ñ—Å—Ç–æ", object: "–õ—å–≤—ñ–≤"}]
check_conflicts:
  ‚îú‚îÄ search("—É–ª—é–±–ª–µ–Ω–µ –º—ñ—Å—Ç–æ")
  ‚îú‚îÄ Found: "–ú–æ—î —É–ª—é–±–ª–µ–Ω–µ –º—ñ—Å—Ç–æ - –•–∞—Ä–∫—ñ–≤" (msg-001)
  ‚îú‚îÄ LLM check_contradiction(old="–•–∞—Ä–∫—ñ–≤", new="–õ—å–≤—ñ–≤")
  ‚îî‚îÄ Result: {is_conflict: true, type: "direct", confidence: 0.9}

auto_resolve:
  ‚îú‚îÄ Decision: ACCEPT new info (Tabula Rasa principle)
  ‚îú‚îÄ Strategy: Replace old fact
  ‚îî‚îÄ Explanation: "Preference changed from –•–∞—Ä–∫—ñ–≤ to –õ—å–≤—ñ–≤"

store_knowledge:
  # Graphiti smart enough to update relations
  # Old: —è -[—É–ª—é–±–ª–µ–Ω–µ –º—ñ—Å—Ç–æ]-> –•–∞—Ä–∫—ñ–≤ (deprecated)
  # New: —è -[—É–ª—é–±–ª–µ–Ω–µ –º—ñ—Å—Ç–æ]-> –õ—å–≤—ñ–≤ (active)
```

---

## Best Practices

### 1. Episode Naming Convention

```python
# TEACH episodes
episode_name = f"teach_{message_uid}"  # teach_msg-001

# –ß–æ–º—É –≤–∞–∂–ª–∏–≤–æ:
# - –£–Ω—ñ–∫–∞–ª—å–Ω—ñ—Å—Ç—å –≥–∞—Ä–∞–Ω—Ç–æ–≤–∞–Ω–∞ (message_uid unique)
# - –õ–µ–≥–∫–æ link–∞—Ç–∏ –∑ Neo4j
# - Prefix "teach_" = semantic meaning
```

### 2. Conflict Detection

```python
# –ö–æ–ª–∏ check_conflicts —à—É–∫–∞—î:
await graphiti.search(query=extracted_fact_text, limit=5)

# –ß–æ–º—É —Ç—ñ–ª—å–∫–∏ 5 results?
# - –ö–æ–Ω—Ñ–ª—ñ–∫—Ç–∏ —à–≤–∏–¥—à–µ –≤—Å—å–æ–≥–æ –≤ top results
# - Reduce LLM calls –¥–ª—è contradiction checking
# - Performance optimization
```

### 3. ReAct Iterations

```python
# –ß–æ–º—É max_iterations = 3?
# - Iteration 1: Initial reasoning + search (—è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ)
# - Iteration 2: Refine based on new context
# - Iteration 3: Final decision
# - –ë—ñ–ª—å—à–µ = diminishing returns + latency
```

### 4. Context Formatting

```python
# –ß–æ–º—É –¥–æ–¥–∞—î–º–æ source_msg_uid –≤ context?
# 1. LLM –±–∞—á–∏—Ç—å –¥–∂–µ—Ä–µ–ª–∞: "[msg-001]: —Ñ–∞–∫—Ç"
# 2. –ú–æ–∂–µ –≤–∫–ª—é—á–∏—Ç–∏ –≤ response: "–ë–∞–∑—É—é—á–∏—Å—å –Ω–∞ [msg-001]..."
# 3. Extract references –ª–µ–≥—à–µ
```

---

## Troubleshooting

### Problem 1: Duplicate episodes

**–°–∏–º–ø—Ç–æ–º:** Same fact –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –¥–≤—ñ—á—ñ

**–ü—Ä–∏—á–∏–Ω–∞:**
```python
# Graphiti –ù–ï –º–∞—î built-in deduplication!
# –ö–æ–∂–µ–Ω add_episode —Å—Ç–≤–æ—Ä—é—î –Ω–æ–≤–∏–π Episode node
```

**–†—ñ—à–µ–Ω–Ω—è:**
- check_conflicts_node –¥–µ—Ç–µ–∫—Ç—É—î duplicates
- auto_resolve_node –ø—Ä–∏–π–º–∞—î –Ω–æ–≤–∏–π (Tabula Rasa)
- LLM –≤ Graphiti –º–æ–∂–µ merge entities (—è–∫—â–æ same name)

### Problem 2: Low relevance scores

**–°–∏–º–ø—Ç–æ–º:** retrieve_context –ø–æ–≤–µ—Ä—Ç–∞—î irrelevant results

**–ü—Ä–∏—á–∏–Ω–∞:**
```python
# 1. Query too vague
# 2. Embeddings –Ω–µ –∑—Ä–æ–∑—É–º—ñ–ª–∏ Ukrainian
# 3. Threshold –∑–∞–Ω–∞–¥—Ç–æ –Ω–∏–∑—å–∫–∏–π
```

**–†—ñ—à–µ–Ω–Ω—è:**
```python
# –ó–±—ñ–ª—å—à–∏—Ç–∏ threshold
graphiti_relevance_threshold: float = 0.5  # –ë—É–ª–æ 0.3

# –ê–±–æ –ø–æ–∫—Ä–∞—â–∏—Ç–∏ query –≤ ReAct
# ReAct –º–æ–∂–µ reformulate query –Ω–∞ iteration 2
```

### Problem 3: Source UIDs missing

**–°–∏–º–ø—Ç–æ–º:** `source_msg_uid = "unknown"` –≤ retrieved context

**–ü—Ä–∏—á–∏–Ω–∞:**
```python
# Episode –≤ Graphiti –ù–ï –º–∞—î –ø–æ–ª—è episode_name
# –ê–±–æ Neo4j Message –Ω–µ –±—É–≤ created
```

**–†—ñ—à–µ–Ω–Ω—è:**
```python
# –ó–∞–≤–∂–¥–∏ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏ –≤ –æ–±–æ—Ö –º—ñ—Å—Ü—è—Ö:
await graphiti.add_episode(episode_name=name, ...)  # Graphiti
await message_store.save_message(episode_name=name, ...)  # Neo4j

# Check logs:
logger.info(f"Episode saved: {episode_name}")
logger.info(f"Message saved to Neo4j")
```

---

## –í–∏—Å–Ω–æ–≤–∫–∏

### –ö–ª—é—á–æ–≤—ñ –ø—Ä–∏–Ω—Ü–∏–ø–∏

1. **Bidirectional Flow**
   - TEACH path = user ‚Üí agent (learning)
   - SOLVE path = agent ‚Üí user (retrieval + reasoning)

2. **Epistemic Awareness**
   - Confidence scores –¥–ª—è facts
   - Conflict detection –∑ LLM reasoning
   - Source tracking (message UIDs)

3. **Temporal Reasoning**
   - Episodes –∑ timestamps
   - Graphiti –ø—ñ–¥—Ç—Ä–∏–º—É—î temporal queries
   - Preferences –º–æ–∂—É—Ç—å –∑–º—ñ–Ω—é–≤–∞—Ç–∏—Å—å –≤ —á–∞—Å—ñ

4. **Knowledge Quality**
   - Hybrid search (semantic + BM25)
   - Reranking (BGE cross-encoder)
   - Relevance threshold filtering

### –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø—ñ—Ö—É

**Good memory system:**
- ‚úÖ TEACH path –∑–±–µ—Ä—ñ–≥–∞—î —Ç—ñ–ª—å–∫–∏ user facts
- ‚úÖ SOLVE path –ù–ï —Å—Ç–≤–æ—Ä—é—î fake knowledge
- ‚úÖ Conflicts –¥–µ—Ç–µ–∫—Ç—É—é—Ç—å—Å—è —Ç–∞ resolve –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ
- ‚úÖ Source references –¥–æ—Å—Ç—É–ø–Ω—ñ –≤ –≤—ñ–¥–ø–æ–≤—ñ–¥—è—Ö
- ‚úÖ ReAct refines search iteratively

**–©–æ –ù–ï —Ä–æ–±–∏—Ç–∏:**
- ‚ùå –ó–±–µ—Ä—ñ–≥–∞—Ç–∏ AI-generated –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —è–∫ facts
- ‚ùå Skip conflict checking (–º–æ–∂–µ overwrite –≤–∞–∂–ª–∏–≤—ñ facts)
- ‚ùå –Ü–≥–Ω–æ—Ä—É–≤–∞—Ç–∏ source UIDs (no references)
- ‚ùå –ó–±–µ—Ä—ñ–≥–∞—Ç–∏ episodic memory –±–µ–∑ timestamps

---

## Roadmap

### Potential Improvements

1. **Memory Consolidation**
   - Periodic merge similar entities
   - Deduplicate episodes
   - Archive old/irrelevant facts

2. **Advanced Conflict Resolution**
   - User confirmation –¥–ª—è critical conflicts
   - Confidence-based merging
   - Multi-source fact verification

3. **Enhanced Retrieval**
   - Query expansion –≤ ReAct
   - Multi-hop reasoning –≤ graph
   - Contextual reranking

4. **Performance Optimization**
   - Cache frequent searches
   - Batch embedding generation
   - Async parallel searches

---

**–ê–≤—Ç–æ—Ä:** Tabula Rasa Agent Team
**–î–∞—Ç–∞:** 2024-01-11
**–í–µ—Ä—Å—ñ—è:** 2.0 (teach/solve architecture)