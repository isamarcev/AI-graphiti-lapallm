"""
Node 8: Answer Generation
–ì–µ–Ω–µ—Ä—É—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑ –û–ë–û–í'–Ø–ó–ö–û–í–ò–ú–ò references –¥–æ –¥–∂–µ—Ä–µ–ª.
"""

import logging
from typing import Dict, Any
from agent.state import AgentState
from agent.helpers import extract_used_sources
from clients.llm_client import get_llm_client
from langsmith import traceable

logger = logging.getLogger(__name__)


@traceable(name="generate_answer")
async def generate_answer_node(state: AgentState) -> Dict[str, Any]:
    """
    –ì–µ–Ω–µ—Ä—É—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å –±–∞–∑—É—é—á–∏—Å—å –Ω–∞:
    - Retrieved context (–∑ source UIDs)
    - ReAct reasoning steps
    
    –ö–†–ò–¢–ò–ß–ù–û: –ö–æ–∂–Ω–µ —Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è –º–∞—î –º–∞—Ç–∏ reference –¥–æ –¥–∂–µ—Ä–µ–ª–∞.
    
    Implements epistemic transparency:
    - Explicit source citations –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ fact
    - Clear indication –∫–æ–ª–∏ knowledge insufficient
    - Reasoning trace –¥–ª—è accountability
    
    Args:
        state: Current agent state with retrieved_context and react_steps
    
    Returns:
        State update with:
        - response: final answer with citations
        - references: list of source message UIDs
        - reasoning: ReAct reasoning summary
    """
    logger.info("=== Generate Answer Node ===")
    
    llm = get_llm_client()
    
    # Build context –∑ explicit source IDs
    retrieved_context = state.get("retrieved_context", [])
    context_parts = []
    
    for i, ctx in enumerate(retrieved_context):
        source_id = ctx.get("source_msg_uid", "unknown")
        content = ctx.get("content", "")
        score = ctx.get("score", 0.0)
        
        context_parts.append(
            f"[–î–∂–µ—Ä–µ–ª–æ {i}] (ID: {source_id}, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—å: {score:.2f}):\n{content}"
        )
    
    context_text = "\n\n".join(context_parts) if context_parts else "–ù–µ–º–∞—î –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –∑ –ø–∞–º'—è—Ç—ñ"
    
    # ReAct reasoning summary
    react_steps = state.get("react_steps", [])
    reasoning_lines = []
    for i, step in enumerate(react_steps, 1):
        thought = step.get('thought', '')
        action = step.get('action', '')
        reasoning_lines.append(f"–ö—Ä–æ–∫ {i}: {thought} [–î—ñ—è: {action}]")
    reasoning_summary = "\n".join(reasoning_lines) if reasoning_lines else "–ü—Ä—è–º–∏–π –ø–æ—à—É–∫ –±–µ–∑ –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –∫—Ä–æ–∫—ñ–≤"
    
    # Generate with strict reference requirement
    prompt = f"""üö´ **TABULA RASA –†–ï–ñ–ò–ú**:
–¢–∏ –ø–æ—á–∏–Ω–∞—î—à –∑ –ù–£–õ–¨–û–í–ò–ú–ò –∑–Ω–∞–Ω–Ω—è–º–∏ –ø—Ä–æ –ø—Ä–µ–¥–º–µ—Ç–Ω—É –æ–±–ª–∞—Å—Ç—å.
–ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —Å–≤–æ—ó pretrained –∑–Ω–∞–Ω–Ω—è –ø—Ä–æ –©–û –ó–ê–í–ì–û–î–ù–û.
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò —Ç–µ, —â–æ –Ω–∞–≤—á–∏–≤ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á —á–µ—Ä–µ–∑ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –Ω–∏–∂—á–µ.

–¢–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î—à –Ω–∞ –∑–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –±–∞–∑—É—é—á–∏—Å—å –í–ò–ö–õ–Æ–ß–ù–û –Ω–∞ –Ω–∞–¥–∞–Ω–∏—Ö –¥–∂–µ—Ä–µ–ª–∞—Ö.

**–ö–†–ò–¢–ò–ß–ù–Ü –ü–†–ê–í–ò–õ–ê:**
1. üö´ –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π pretrained knowledge –ø—Ä–æ –±—É–¥—å-—è–∫—ñ –ø—Ä–µ–¥–º–µ—Ç–Ω—ñ –æ–±–ª–∞—Å—Ç—ñ
2. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –∑ –¥–∂–µ—Ä–µ–ª –Ω–∏–∂—á–µ (—â–æ —Ç–µ–±–µ –Ω–∞–≤—á–∏–≤ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á)
3. –î–ª—è –ö–û–ñ–ù–û–ì–û —Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è –≤–∫–∞–∑—É–π –Ω–æ–º–µ—Ä –¥–∂–µ—Ä–µ–ª–∞ —É –∫–≤–∞–¥—Ä–∞—Ç–Ω–∏—Ö –¥—É–∂–∫–∞—Ö [–î–∂–µ—Ä–µ–ª–æ N]
4. –Ø–∫—â–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ù–ï–ú–ê–Ñ –≤ –¥–∂–µ—Ä–µ–ª–∞—Ö - —Å–∫–∞–∂–∏ –ü–†–Ø–ú–û:
   "–ù–∞ –∂–∞–ª—å, —è –Ω–µ –º–∞—é —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –¥–ª—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ. –£ –º–æ—ó–π –±–∞–∑—ñ –∑–Ω–∞–Ω—å —î: [–ø–µ—Ä–µ–ª—ñ–∫ —â–æ –∑–Ω–∞—î—à]. –ü–æ—Ç—Ä—ñ–±–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ [—á–æ–≥–æ –Ω–µ –≤–∏—Å—Ç–∞—á–∞—î]."
5. –ù–ï –≤–∏–≥–∞–¥—É–π, –ù–ï –∑–¥–æ–≥–∞–¥—É–π—Å—è, –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –∑–∞–≥–∞–ª—å–Ω—ñ –∑–Ω–∞–Ω–Ω—è
6. –Ø–∫—â–æ –¥–∂–µ—Ä–µ–ª–∞ —Å—É–ø–µ—Ä–µ—á–∞—Ç—å - –≤–∫–∞–∂–∏ —Ü–µ —è–≤–Ω–æ –∑ references

**–Ø–ö–©–û –ó–ê–í–î–ê–ù–ù–Ø - –°–¢–í–û–†–ï–ù–ù–Ø/–ì–ï–ù–ï–†–ê–¶–Ü–Ø (–ø—Ä–æ—Ü–µ–¥—É—Ä–∏, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏, –∞–ª–≥–æ—Ä–∏—Ç–º—É):**
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò —Å—Ç—Ä—É–∫—Ç—É—Ä–∏/—Å–∏–Ω—Ç–∞–∫—Å–∏—Å/–ø—Ä–æ—Ü–µ–¥—É—Ä–∏ –∑ –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
- –ö–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∞ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è = reference [–î–∂–µ—Ä–µ–ª–æ N]
- –Ø–∫—â–æ –Ω–µ –Ω–∞–≤—á–∏–ª–∏ –ø–æ—Ç—Ä—ñ–±–Ω—É –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—é - —Å–∫–∞–∂–∏ –ü–†–Ø–ú–û —â–æ –Ω–µ –≤–∏—Å—Ç–∞—á–∞—î
- –ù–ï —ñ–º–ø—Ä–æ–≤—ñ–∑—É–π, –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π "–∑–∞–≥–∞–ª—å–Ω–æ–ø—Ä–∏–π–Ω—è—Ç—ñ" –ø—ñ–¥—Ö–æ–¥–∏

**–ü–†–ò–ö–õ–ê–î –ü–†–ê–í–ò–õ–¨–ù–û–á –í–Ü–î–ü–û–í–Ü–î–Ü (–∫–æ–ª–∏ —î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è):**
"–û—Å—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –±–∞–∑—É—é—á–∏—Å—å –Ω–∞ [–î–∂–µ—Ä–µ–ª–æ 2]:
[–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑ –¥–∂–µ—Ä–µ–ª–∞]

–í–∏–∫–æ—Ä–∏—Å—Ç–∞–≤ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å –∑ [–î–∂–µ—Ä–µ–ª–æ 2]: [–ø–æ—è—Å–Ω–µ–Ω–Ω—è]"

**–ü–†–ò–ö–õ–ê–î –ö–û–õ–ò –ù–ï –ù–ê–í–ß–ï–ù–ò–ô:**
"–ù–∞ –∂–∞–ª—å, —è —â–µ –Ω–µ –Ω–∞–≤—á–µ–Ω–∏–π —è–∫ —Ä–æ–±–∏—Ç–∏ X. –£ –º–æ—ó–π –±–∞–∑—ñ –∑–Ω–∞–Ω—å —î:
- [—Ñ–∞–∫—Ç 1] [–î–∂–µ—Ä–µ–ª–æ 3]
- [—Ñ–∞–∫—Ç 2] [–î–∂–µ—Ä–µ–ª–æ 5]

–ü–æ—Ç—Ä—ñ–±–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ [–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ —á–æ–≥–æ –Ω–µ –≤–∏—Å—Ç–∞—á–∞—î]."

–ö–û–ù–¢–ï–ö–°–¢ –ó –ü–ê–ú'–Ø–¢–Ü (—â–æ —Ç–µ–±–µ –Ω–∞–≤—á–∏–ª–∏):
{context_text}

–ü–†–û–¶–ï–° –ú–Ü–†–ö–£–í–ê–ù–ù–Ø (ReAct):
{reasoning_summary}

–ó–ê–ü–ò–¢ –ö–û–†–ò–°–¢–£–í–ê–ß–ê: {state['message_text']}

–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é. –û–±–æ–≤'—è–∑–∫–æ–≤–æ –≤–∫–∞–∑—É–π –¥–∂–µ—Ä–µ–ª–∞ —É —Ñ–æ—Ä–º–∞—Ç—ñ [–î–∂–µ—Ä–µ–ª–æ N]."""
    
    try:
        response_text = await llm.generate_async(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=1024
        )
        
        logger.debug(f"Generated response: {response_text[:200]}...")
        
        # Extract –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ –¥–∂–µ—Ä–µ–ª–∞ –∑ —Ç–µ–∫—Å—Ç—É
        used_source_indices = extract_used_sources(response_text)
        
        # Map indices to actual message UIDs
        used_sources = set()
        for idx in used_source_indices:
            if idx < len(retrieved_context):
                source_uid = retrieved_context[idx].get("source_msg_uid")
                if source_uid and source_uid != "unknown":
                    used_sources.add(source_uid)
                    logger.debug(f"Using source {idx}: {source_uid}")
        
        # –î–æ–¥–∞—Ç–∏ current message UID —è–∫ reference
        references = list(used_sources)
        if state["message_uid"] not in references:
            references.append(state["message_uid"])
        
        logger.info(f"Generated answer with {len(references)} references")
        
        # Check if response indicates insufficient knowledge
        insufficient_indicators = [
            "–Ω–µ –º–∞—é",
            "–Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó",
            "–Ω–µ–º–∞—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó",
            "–Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"
        ]
        if any(indicator in response_text.lower() for indicator in insufficient_indicators):
            logger.warning("Agent indicates insufficient knowledge to answer")
        
        return {
            "response": response_text,
            "references": references,
            "reasoning": reasoning_summary
        }
        
    except Exception as e:
        logger.error(f"Error generating answer: {e}", exc_info=True)
        return {
            "response": f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {str(e)}",
            "references": [state["message_uid"]],
            "reasoning": None
        }
