"""
Node 7: ReAct Loop
Implements ReAct (Reasoning + Acting) for complex task solving.
"""

import json
import logging
import re
from typing import Dict, Any, List, Optional

from pydantic import BaseModel

from agent.state import AgentState
from clients.llm_client import get_llm_client
from clients.graphiti_client import get_graphiti_client
from config.settings import settings
from langsmith import traceable

logger = logging.getLogger(__name__)

ACTION_ANSWER = "answer"
ACTION_SEARCH = "search"
ALLOWED_ACTIONS = {ACTION_ANSWER, ACTION_SEARCH}
ANSWER_KEYWORDS = ("–≥–æ—Ç–æ–≤–∏–π", "–¥–æ—Å—Ç–∞—Ç–Ω—å–æ", "–º–æ–∂—É –≤—ñ–¥–ø–æ–≤—ñ—Å—Ç–∏", "answer", "ready")
SEARCH_KEYWORDS = ("—à—É–∫–∞—Ç–∏", "–∑–Ω–∞–π—Ç–∏", "–ø–æ—Ç—Ä—ñ–±–Ω–æ", "search", "find", "need")


class ReactStep(BaseModel):
    thought: str
    action: str
    query: Optional[str] = None


def _build_context_text(retrieved_context: List[Dict[str, Any]]) -> str:
    return "\n".join(
        f"[{i}] ({ctx.get('source_msg_uid', 'unknown')}): {ctx.get('content', '')}"
        for i, ctx in enumerate(retrieved_context)
    )


def _build_history_text(steps: List[Dict[str, Any]]) -> str:
    return "\n".join(
        "–ö—Ä–æ–∫ {idx}:\n  –î—É–º–∫–∞: {thought}\n  –î—ñ—è: {action}\n  –†–µ–∑—É–ª—å—Ç–∞—Ç: {observation}".format(
            idx=i + 1,
            thought=step.get("thought", ""),
            action=step.get("action", ""),
            observation=(step.get("observation", "")[:200] + "...") if step.get("observation") else "",
        )
        for i, step in enumerate(steps)
    )


def _build_thought_prompt(task: str, context_text: str, history_text: Optional[str], iteration: int) -> str:
    if iteration == 0:
        return f"""üö´ TABULA RASA: –£ —Ç–µ–±–µ –ù–£–õ–¨–û–í–Ü –∑–Ω–∞–Ω–Ω—è –ø—Ä–æ –ø—Ä–µ–¥–º–µ—Ç–Ω—É –æ–±–ª–∞—Å—Ç—å.
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –Ω–∏–∂—á–µ. –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π pretrained knowledge.

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∑ –ø–∞–º'—è—Ç—ñ (—â–æ —Ç–µ–±–µ –Ω–∞–≤—á–∏–ª–∏):
{context_text if context_text else "(–ø–æ—Ä–æ–∂–Ω—å–æ - –Ω—ñ—á–æ–≥–æ –Ω–µ –Ω–∞–≤—á–∏–ª–∏)"}

–ó–∞–≤–¥–∞–Ω–Ω—è: {task}

–ü–æ—Ç—Ä—ñ–±–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON –∑ –∫–ª—é—á–∞–º–∏:
  thought: –∫–æ—Ä–æ—Ç–∫–∏–π –≤–∏–∫–ª–∞–¥ –ª–æ–≥—ñ–∫–∏
  action: "answer" –∞–±–æ "search"
  query: —Ä—è–¥–æ–∫ –∑–∞–ø–∏—Ç—É, —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ action == "search"

–Ø–∫—â–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–ª—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ, –≤–∏–±–µ—Ä–∏ action="answer".
–Ø–∫—â–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –ù–ï–ú–ê–Ñ –ø–æ—Ç—Ä—ñ–±–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó, –≤–∏–±–µ—Ä–∏ action="search" —ñ —Å—Ñ–æ—Ä–º—É–ª—é–π –∑–∞–ø–∏—Ç.

JSON –≤—ñ–¥–ø–æ–≤—ñ–¥—å:"""

    return f"""üö´ TABULA RASA: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É. –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π pretrained knowledge.

–ü–æ–ø–µ—Ä–µ–¥–Ω—ñ –∫—Ä–æ–∫–∏:
{history_text or "(–Ω–µ–º–∞—î)"}

–ü–æ—Ç–æ—á–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—â–æ —Ç–µ–±–µ –Ω–∞–≤—á–∏–ª–∏):
{context_text}

–ó–∞–≤–¥–∞–Ω–Ω—è: {task}

–ü–æ—Ç—Ä—ñ–±–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON –∑ –∫–ª—é—á–∞–º–∏:
  thought: –∫–æ—Ä–æ—Ç–∫–∏–π –≤–∏–∫–ª–∞–¥ –ª–æ–≥—ñ–∫–∏
  action: "answer" –∞–±–æ "search"
  query: —Ä—è–¥–æ–∫ –∑–∞–ø–∏—Ç—É, —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ action == "search"

JSON –≤—ñ–¥–ø–æ–≤—ñ–¥—å:"""


def _extract_json_payload(text: str) -> Optional[Dict[str, Any]]:
    cleaned = text.strip()
    # Try direct JSON
    try:
        data = json.loads(cleaned)
        if isinstance(data, dict):
            return data
    except json.JSONDecodeError:
        pass

    # Try to find JSON object within text (incl. fenced blocks)
    match = re.search(r"\{.*\}", cleaned, flags=re.DOTALL)
    if not match:
        return None
    try:
        data = json.loads(match.group(0))
        if isinstance(data, dict):
            return data
    except json.JSONDecodeError:
        return None
    return None


def _normalize_action(action: str) -> str:
    action_lower = action.strip().lower()
    if action_lower in ALLOWED_ACTIONS:
        return action_lower
    return ACTION_ANSWER


def _infer_action_from_thought(thought: str) -> str:
    thought_lower = thought.lower()
    if any(keyword in thought_lower for keyword in ANSWER_KEYWORDS):
        return ACTION_ANSWER
    if any(keyword in thought_lower for keyword in SEARCH_KEYWORDS):
        return ACTION_SEARCH
    return ACTION_ANSWER


def _parse_react_response(response_text: str) -> Dict[str, Any]:
    payload = _extract_json_payload(response_text)
    if payload:
        thought = str(payload.get("thought", "")).strip()
        action = _normalize_action(str(payload.get("action", "")))
        query = str(payload.get("query", "")).strip()
        if action == ACTION_SEARCH and not query:
            query = thought
        return {"thought": thought, "action": action, "query": query}

    # Fallback: treat entire output as thought and infer action
    thought = response_text.strip()
    action = _infer_action_from_thought(thought)
    return {"thought": thought, "action": action, "query": ""}


@traceable(name="react_loop")
async def react_loop_node(state: AgentState) -> Dict[str, Any]:
    """
    Node 7: ReAct (Reasoning + Acting) loop.

    Iteratively:
    1. THOUGHT - what needs to be done
    2. ACTION - search for more context OR generate answer
    3. OBSERVATION - result of action

    Continues until:
    - Max iterations reached
    - Action is "answer" (ready to respond)

    Args:
        state: Current agent state

    Returns:
        State update with react_steps
    """
    logger.info("=== ReAct Loop Node ===")

    max_iterations = getattr(settings, 'max_react_iterations', 3)
    logger.info(f"Max iterations: {max_iterations}")

    llm = get_llm_client()
    graphiti = await get_graphiti_client()

    # Build initial context
    retrieved_context = state.get("retrieved_context", [])
    context_text = _build_context_text(retrieved_context)

    task = state["message_text"]
    steps: List[Dict[str, Any]] = []

    for iteration in range(max_iterations):
        logger.info(f"\n--- ReAct Iteration {iteration + 1}/{max_iterations} ---")

        history_text = _build_history_text(steps) if steps else None
        thought_prompt = _build_thought_prompt(task, context_text, history_text, iteration)

        # Generate thought
        try:
            structured = await llm.generate_async(
                messages=[{"role": "user", "content": thought_prompt}],
                temperature=0.3,
                max_tokens=200,
                response_format=ReactStep
            )
            thought = structured.thought.strip()
            action = _normalize_action(structured.action)
            search_query = (structured.query or "").strip()
            if action == ACTION_SEARCH and not search_query:
                search_query = thought
            logger.info(f"Thought: {thought}")
            logger.info(f"Action: {action}")
        except Exception as e:
            logger.warning("Structured output failed, falling back to text parsing", exc_info=True)
            try:
                thought_response = await llm.generate_async(
                    messages=[{"role": "user", "content": thought_prompt}],
                    temperature=0.3,
                    max_tokens=200
                )
                parsed = _parse_react_response(thought_response)
                thought = parsed["thought"]
                action = parsed["action"]
                search_query = parsed["query"]
                logger.info(f"Thought: {thought}")
                logger.info(f"Action: {action}")
            except Exception as inner_exc:
                logger.error(f"Error generating thought: {inner_exc}")
                thought = "–ì–æ—Ç–æ–≤–∏–π –≤—ñ–¥–ø–æ–≤—ñ—Å—Ç–∏ –∑ –Ω–∞—è–≤–Ω–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"
                action = ACTION_ANSWER
                search_query = ""

        if action == ACTION_ANSWER:
            observation = "–ì–æ—Ç–æ–≤–æ –¥–æ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ"
            steps.append({"thought": thought, "action": action, "observation": observation})
            break

        if action == ACTION_SEARCH:
            # Extract search query from thought if missing
            if not search_query:
                search_query = extract_search_query(thought) or task
            logger.info(f"Action: {action} - Query: {search_query}")

            try:
                search_results = await graphiti.search(query=search_query, limit=3)
                observation = format_search_results(search_results)
                logger.info(f"Observation: Found {len(search_results)} results")

                for result in search_results:
                    content = result.get("content", "") or result.get("fact", "")
                    if content:
                        context_text += f"\n{content}"
            except Exception as e:
                logger.error(f"Error during search: {e}")
                observation = f"–ü–æ–º–∏–ª–∫–∞ –ø–æ—à—É–∫—É: {e}"

            steps.append({"thought": thought, "action": action, "observation": observation})
            continue

        # Safety fallback
        observation = "–ü—Ä–∏—Å—Ç—É–ø–∞—é –¥–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ"
        steps.append({"thought": thought, "action": ACTION_ANSWER, "observation": observation})
        break

    logger.info(f"ReAct loop completed after {len(steps)} steps")

    return {
        "react_steps": steps
    }
