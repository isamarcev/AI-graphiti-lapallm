"""
Node 7: ReAct Loop
Implements ReAct (Reasoning + Acting) for complex task solving.
"""

import json
import logging
import re
from typing import Dict, Any, List, Optional, Set

from pydantic import BaseModel

from agent.helpers import format_search_results
from agent.state import AgentState
from clients.llm_client import get_llm_client
from clients.qdrant_client import QdrantClient
from clients.hosted_embedder import get_embedder
from config.settings import settings
from langsmith import traceable

logger = logging.getLogger(__name__)

ACTION_ANSWER = "answer"
ACTION_SEARCH = "search"
ALLOWED_ACTIONS = {ACTION_ANSWER, ACTION_SEARCH}
ANSWER_KEYWORDS = ("–≥–æ—Ç–æ–≤–∏–π", "–¥–æ—Å—Ç–∞—Ç–Ω—å–æ", "–º–æ–∂—É –≤—ñ–¥–ø–æ–≤—ñ—Å—Ç–∏", "answer", "ready")
SEARCH_KEYWORDS = ("—à—É–∫–∞—Ç–∏", "–∑–Ω–∞–π—Ç–∏", "–ø–æ—Ç—Ä—ñ–±–Ω–æ", "search", "find", "need")

MIN_QUERY_LENGTH = 3  # Minimum query length in characters


class ReactStep(BaseModel):
    thought: str
    action: str
    query: Optional[str] = None


def _build_context_text(retrieved_context: List[Dict[str, Any]]) -> str:
    return "\n".join(
        f"[{i}] ({ctx.get('source_msg_uid', 'unknown')}): {ctx.get('content', '')}"
        for i, ctx in enumerate(retrieved_context)
    )


def _build_history_text(steps: List[Dict[str, Any]]) -> str:
    return "\n".join(
        "–ö—Ä–æ–∫ {idx}:\n  –î—É–º–∫–∞: {thought}\n  –î—ñ—è: {action}\n  –†–µ–∑—É–ª—å—Ç–∞—Ç: {observation}".format(
            idx=i + 1,
            thought=step.get("thought", ""),
            action=step.get("action", ""),
            observation=(step.get("observation", "")[:200] + "...") if step.get("observation") else "",
        )
        for i, step in enumerate(steps)
    )


def _build_thought_prompt(task: str, context_text: str, history_text: Optional[str], iteration: int) -> str:
    if iteration == 0:
        return f"""üö´ TABULA RASA: –£ —Ç–µ–±–µ –ù–£–õ–¨–û–í–Ü –∑–Ω–∞–Ω–Ω—è –ø—Ä–æ –ø—Ä–µ–¥–º–µ—Ç–Ω—É –æ–±–ª–∞—Å—Ç—å.
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –Ω–∏–∂—á–µ. –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π pretrained knowledge.

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∑ –ø–∞–º'—è—Ç—ñ (—â–æ —Ç–µ–±–µ –Ω–∞–≤—á–∏–ª–∏):
{context_text if context_text else "(–ø–æ—Ä–æ–∂–Ω—å–æ - –Ω—ñ—á–æ–≥–æ –Ω–µ –Ω–∞–≤—á–∏–ª–∏)"}

–ó–∞–≤–¥–∞–Ω–Ω—è: {task}

–§–û–†–ú–ê–¢ –í–Ü–î–ü–û–í–Ü–î–Ü - JSON –∑ –∫–ª—é—á–∞–º–∏:
  "thought": –∫–æ—Ä–æ—Ç–∫–∏–π –≤–∏–∫–ª–∞–¥ —Ç–≤–æ—î—ó –ª–æ–≥—ñ–∫–∏ (1-2 —Ä–µ—á–µ–Ω–Ω—è)
  "action": "answer" –∞–±–æ "search"
  "query": –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π –ø–æ—à—É–∫–æ–≤–∏–π –∑–∞–ø–∏—Ç (–û–ë–û–í'–Ø–ó–ö–û–í–û —è–∫—â–æ action="search")

–ü–†–ê–í–ò–õ–ê:
- –Ø–∫—â–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –Ñ –¥–æ—Å—Ç–∞—Ç–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è ‚Üí action="answer", query –º–æ–∂–Ω–∞ –Ω–µ –≤–∫–∞–∑—É–≤–∞—Ç–∏
- –Ø–∫—â–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –ù–ï–ú–ê–Ñ –ø–æ—Ç—Ä—ñ–±–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó ‚Üí action="search", query –û–ë–û–í'–Ø–ó–ö–û–í–ò–ô
- query –º–∞—î –±—É—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–º (2-5 –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤), –ù–ï –ø–æ–≤–Ω–∏–º —Ä–µ—á–µ–Ω–Ω—è–º
- query –º–∞—î –≤—ñ–¥–æ–±—Ä–∞–∂–∞—Ç–∏ –©–û —Å–∞–º–µ —à—É–∫–∞—Ç–∏, –∞ –Ω–µ "–ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–Ω–∞–π—Ç–∏..."

–ü–†–ò–ö–õ–ê–î–ò:
{{"thought": "–í –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –Ω–µ–º–∞—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ —Å—Ç–æ–ª–∏—Ü—é", "action": "search", "query": "—Å—Ç–æ–ª–∏—Ü—è –£–∫—Ä–∞—ó–Ω–∏"}}
{{"thought": "–ö–æ–Ω—Ç–µ–∫—Å—Ç –º—ñ—Å—Ç–∏—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥—å –ø—Ä–æ –ö–∏—ó–≤", "action": "answer"}}
{{"thought": "–¢—Ä–µ–±–∞ –¥—ñ–∑–Ω–∞—Ç–∏—Å—å –ø—Ä–æ —É–ª—é–±–ª–µ–Ω—É —ó–∂—É", "action": "search", "query": "—É–ª—é–±–ª–µ–Ω–∞ —ó–∂–∞ –û–ª–µ–≥–∞"}}

JSON –≤—ñ–¥–ø–æ–≤—ñ–¥—å:"""

    return f"""üö´ TABULA RASA: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É. –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π pretrained knowledge.

–ü–æ–ø–µ—Ä–µ–¥–Ω—ñ –∫—Ä–æ–∫–∏:
{history_text or "(–Ω–µ–º–∞—î)"}

–ü–æ—Ç–æ—á–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—â–æ —Ç–µ–±–µ –Ω–∞–≤—á–∏–ª–∏):
{context_text}

–ó–∞–≤–¥–∞–Ω–Ω—è: {task}

–§–û–†–ú–ê–¢ –í–Ü–î–ü–û–í–Ü–î–Ü - JSON –∑ –∫–ª—é—á–∞–º–∏:
  "thought": –∫–æ—Ä–æ—Ç–∫–∏–π –≤–∏–∫–ª–∞–¥ —Ç–≤–æ—î—ó –ª–æ–≥—ñ–∫–∏ (1-2 —Ä–µ—á–µ–Ω–Ω—è)
  "action": "answer" –∞–±–æ "search"
  "query": –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π –ø–æ—à—É–∫–æ–≤–∏–π –∑–∞–ø–∏—Ç (–û–ë–û–í'–Ø–ó–ö–û–í–û —è–∫—â–æ action="search")

–ü–†–ê–í–ò–õ–ê:
- –Ø–∫—â–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –Ñ –¥–æ—Å—Ç–∞—Ç–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è ‚Üí action="answer"
- –Ø–∫—â–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –ù–ï–ú–ê–Ñ –ø–æ—Ç—Ä—ñ–±–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó ‚Üí action="search" + query –û–ë–û–í'–Ø–ó–ö–û–í–ò–ô
- query –º–∞—î –±—É—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–º (2-5 –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤), –ù–ï –ø–æ–≤–Ω–∏–º —Ä–µ—á–µ–Ω–Ω—è–º
- –ù–ï –ø–æ–≤—Ç–æ—Ä—é–π –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ –∑–∞–ø–∏—Ç–∏, —à—É–∫–∞–π —â–æ—Å—å –Ω–æ–≤–µ

JSON –≤—ñ–¥–ø–æ–≤—ñ–¥—å:"""


def _extract_json_payload(text: str) -> Optional[Dict[str, Any]]:
    cleaned = text.strip()
    # Try direct JSON
    try:
        data = json.loads(cleaned)
        if isinstance(data, dict):
            return data
    except json.JSONDecodeError:
        pass

    # Try to find JSON object within text (incl. fenced blocks)
    match = re.search(r"\{.*\}", cleaned, flags=re.DOTALL)
    if not match:
        return None
    try:
        data = json.loads(match.group(0))
        if isinstance(data, dict):
            return data
    except json.JSONDecodeError:
        return None
    return None


def _normalize_action(action: str) -> str:
    action_lower = action.strip().lower()
    if action_lower in ALLOWED_ACTIONS:
        return action_lower
    return ACTION_ANSWER


def _infer_action_from_thought(thought: str) -> str:
    thought_lower = thought.lower()
    if any(keyword in thought_lower for keyword in ANSWER_KEYWORDS):
        return ACTION_ANSWER
    if any(keyword in thought_lower for keyword in SEARCH_KEYWORDS):
        return ACTION_SEARCH
    return ACTION_ANSWER


def _parse_react_response(response_text: str) -> Dict[str, Any]:
    payload = _extract_json_payload(response_text)
    if payload:
        thought = str(payload.get("thought", "")).strip()
        action = _normalize_action(str(payload.get("action", "")))
        query = str(payload.get("query", "")).strip()
        return {"thought": thought, "action": action, "query": query}

    # Fallback: treat entire output as thought and infer action
    thought = response_text.strip()
    action = _infer_action_from_thought(thought)
    return {"thought": thought, "action": action, "query": ""}


def _is_valid_query(query: Optional[str]) -> bool:
    """
    Validate if search query is meaningful.
    
    Args:
        query: Search query string
        
    Returns:
        True if query is valid for search
    """
    if not query or not query.strip():
        return False
    
    query_clean = query.strip()
    
    # Too short
    if len(query_clean) < MIN_QUERY_LENGTH:
        return False
    
    # Only punctuation or whitespace
    if not re.search(r'[–∞-—è–ê-–Ø—ñ–Ü—ó–á—î–Ña-zA-Z0-9]', query_clean):
        return False
    
    return True


def _validate_react_step(thought: str, action: str, query: Optional[str]) -> tuple[bool, str]:
    """
    Validate ReAct step output from LLM.
    
    Args:
        thought: Agent's reasoning
        action: Action to take
        query: Search query (required if action is search)
        
    Returns:
        (is_valid, error_message) tuple
    """
    if not thought:
        return False, "Thought is empty"
    
    if action not in ALLOWED_ACTIONS:
        return False, f"Invalid action: {action}"
    
    # If action is search, query must be valid
    if action == ACTION_SEARCH:
        if not _is_valid_query(query):
            return False, f"Search action requires valid query, got: '{query}'"
    
    return True, ""


@traceable(name="react_loop")
async def react_loop_node(state: AgentState) -> Dict[str, Any]:
    """
    Node 7: ReAct (Reasoning + Acting) loop.

    Iteratively:
    1. THOUGHT - what needs to be done
    2. ACTION - search for more context OR generate answer
    3. OBSERVATION - result of action

    Continues until:
    - Max iterations reached
    - Action is "answer" (ready to respond)

    Args:
        state: Current agent state

    Returns:
        State update with react_steps
    """
    logger.info("=== ReAct Loop Node ===")

    max_iterations = getattr(settings, 'max_react_iterations', 3)
    logger.info(f"Max iterations: {max_iterations}")

    llm = get_llm_client()
    embedder = get_embedder()
    qdrant = QdrantClient()
    await qdrant.initialize()

    # Build initial context
    retrieved_context = state.get("retrieved_context", [])
    context_text = _build_context_text(retrieved_context)

    task = state["message_text"]
    steps: List[Dict[str, Any]] = []
    searched_queries: Set[str] = set()  # Track queries to avoid duplicates

    for iteration in range(max_iterations):
        logger.info(f"\n--- ReAct Iteration {iteration + 1}/{max_iterations} ---")

        history_text = _build_history_text(steps) if steps else None
        thought_prompt = _build_thought_prompt(task, context_text, history_text, iteration)

        # Generate thought with structured output
        thought = ""
        action = ACTION_ANSWER
        search_query = ""
        
        try:
            structured = await llm.generate_async(
                messages=[{"role": "user", "content": thought_prompt}],
                temperature=0.3,
                max_tokens=200,
                response_format=ReactStep
            )
            thought = structured.thought.strip()
            action = _normalize_action(structured.action)
            search_query = (structured.query or "").strip()
            
            logger.info(f"Thought: {thought}")
            logger.info(f"Action: {action}")
            if search_query:
                logger.info(f"Query: {search_query}")
                
        except Exception as e:
            logger.warning("Structured output failed, falling back to text parsing", exc_info=True)
            try:
                thought_response = await llm.generate_async(
                    messages=[{"role": "user", "content": thought_prompt}],
                    temperature=0.3,
                    max_tokens=200
                )
                parsed = _parse_react_response(thought_response)
                thought = parsed["thought"]
                action = parsed["action"]
                search_query = parsed["query"]
                
                logger.info(f"Thought: {thought}")
                logger.info(f"Action: {action}")
                if search_query:
                    logger.info(f"Query: {search_query}")
                    
            except Exception as inner_exc:
                logger.error(f"Error generating thought: {inner_exc}")
                thought = "–ì–æ—Ç–æ–≤–∏–π –≤—ñ–¥–ø–æ–≤—ñ—Å—Ç–∏ –∑ –Ω–∞—è–≤–Ω–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"
                action = ACTION_ANSWER
                search_query = ""
        
        # Validate the ReAct step
        is_valid, error_msg = _validate_react_step(thought, action, search_query)
        if not is_valid:
            logger.warning(f"Invalid ReAct step: {error_msg}. Defaulting to answer.")
            observation = f"–ù–µ–≤–∞–ª—ñ–¥–Ω–∏–π –∫—Ä–æ–∫: {error_msg}. –ü–µ—Ä–µ—Ö–æ–¥–∂—É –¥–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ."
            steps.append({"thought": thought, "action": ACTION_ANSWER, "observation": observation})
            break

        if action == ACTION_ANSWER:
            observation = "–ì–æ—Ç–æ–≤–æ –¥–æ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ"
            steps.append({"thought": thought, "action": action, "observation": observation})
            break

        if action == ACTION_SEARCH:
            # Check for duplicate query
            query_normalized = search_query.lower().strip()
            if query_normalized in searched_queries:
                observation = f"–ó–∞–ø–∏—Ç '{search_query}' –≤–∂–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–≤—Å—è. –ü–µ—Ä–µ—Ö–æ–¥–∂—É –¥–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ."
                logger.warning(observation)
                steps.append({"thought": thought, "action": ACTION_ANSWER, "observation": observation})
                break
            
            searched_queries.add(query_normalized)
            
            # Generate embedding for the search query (NOT using original message embedding!)
            try:
                query_vector = await embedder.embed(search_query)
                logger.info(f"Generated embedding for query: '{search_query}'")
            except Exception as e:
                observation = f"–ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó embedding: {e}"
                logger.error(observation, exc_info=True)
                steps.append({"thought": thought, "action": action, "observation": observation})
                continue
            
            # Search in Qdrant with the NEW query embedding
            try:
                search_results = await qdrant.search_similar(
                    query_vector=query_vector,
                    top_k=3,
                    only_relevant=True,
                )

                formatted_results = []
                for hit in search_results:
                    payload = hit.get("payload") or {}
                    formatted_results.append({
                        "content": payload.get("fact") or "",
                        "score": hit.get("score", 0.0),
                        "source_msg_uid": payload.get("messageid") or payload.get("record_id") or "unknown",
                        "timestamp": payload.get("timestamp"),
                    })

                # Update context with new results
                retrieved_context.extend(formatted_results)
                context_text = _build_context_text(retrieved_context)

                observation = format_search_results(formatted_results)
                logger.info(f"Found {len(formatted_results)} results for query '{search_query}'")
                
            except Exception as e:
                observation = f"–ü–æ–º–∏–ª–∫–∞ –ø–æ—à—É–∫—É: {e}"
                logger.error(observation, exc_info=True)

            steps.append({"thought": thought, "action": action, "observation": observation})
            continue

        # Safety fallback
        observation = "–ü—Ä–∏—Å—Ç—É–ø–∞—é –¥–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ"
        steps.append({"thought": thought, "action": ACTION_ANSWER, "observation": observation})
        break

    logger.info(f"ReAct loop completed after {len(steps)} steps")
    logger.info(f"Total context items: {len(retrieved_context)}")

    return {
        "react_steps": steps,
        "retrieved_context": retrieved_context,  # Return updated context
    }
