"""
Node 7: ReAct Loop
Implements ReAct (Reasoning + Acting) for complex task solving.
"""

import logging
from typing import Dict, Any, List

from agent.state import AgentState
from clients.llm_client import get_llm_client
from clients.qdrant_client import QdrantClient
from config.settings import settings
from langsmith import traceable

logger = logging.getLogger(__name__)


@traceable(name="react_loop")
async def react_loop_node(state: AgentState) -> Dict[str, Any]:
    """
    Node 7: ReAct (Reasoning + Acting) loop.

    Iteratively:
    1. THOUGHT - what needs to be done
    2. ACTION - search for more context OR generate answer
    3. OBSERVATION - result of action

    Continues until:
    - Max iterations reached
    - Action is "answer" (ready to respond)

    Args:
        state: Current agent state

    Returns:
        State update with react_steps
    """
    logger.info("=== ReAct Loop Node ===")

    max_iterations = getattr(settings, 'max_react_iterations', 3)
    logger.info(f"Max iterations: {max_iterations}")

    llm = get_llm_client()
    # Lazy-init Qdrant client
    qdrant = QdrantClient()
    await qdrant.initialize()

    # Build initial context
    retrieved_context = state.get("retrieved_context", [])
    context_text = "\n".join([
        f"[{i}] ({ctx['source_msg_uid']}): {ctx['content']}"
        for i, ctx in enumerate(retrieved_context)
    ])

    task = state["message_text"]
    steps: List[Dict[str, Any]] = []

    for iteration in range(max_iterations):
        logger.info(f"\n--- ReAct Iteration {iteration + 1}/{max_iterations} ---")

        # Build prompt for thought
        if iteration == 0:
            thought_prompt = f"""üö´ TABULA RASA: –£ —Ç–µ–±–µ –ù–£–õ–¨–û–í–Ü –∑–Ω–∞–Ω–Ω—è –ø—Ä–æ –ø—Ä–µ–¥–º–µ—Ç–Ω—É –æ–±–ª–∞—Å—Ç—å. 
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –Ω–∏–∂—á–µ. –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π pretrained knowledge.

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∑ –ø–∞–º'—è—Ç—ñ (—â–æ —Ç–µ–±–µ –Ω–∞–≤—á–∏–ª–∏):
{context_text if context_text else "(–ø–æ—Ä–æ–∂–Ω—å–æ - –Ω—ñ—á–æ–≥–æ –Ω–µ –Ω–∞–≤—á–∏–ª–∏)"}

–ó–∞–≤–¥–∞–Ω–Ω—è: {task}

–ö—Ä–æ–∫ 1. –ü–æ–¥—É–º–∞–π: —â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑—Ä–æ–±–∏—Ç–∏ –¥–ª—è –≤–∏—Ä—ñ—à–µ–Ω–Ω—è –∑–∞–≤–¥–∞–Ω–Ω—è?
- –Ø–∫—â–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–ª—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –±–∞–∑—É—é—á–∏—Å—å –¢–Ü–õ–¨–ö–ò –Ω–∞ –Ω–∞–≤–µ–¥–µ–Ω—ñ–π —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó - —Å–∫–∞–∂–∏ "–≥–æ—Ç–æ–≤–∏–π –≤—ñ–¥–ø–æ–≤—ñ—Å—Ç–∏"
- –Ø–∫—â–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –ù–ï–ú–ê–Ñ –ø–æ—Ç—Ä—ñ–±–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó - –æ–ø–∏—à–∏ —â–æ —Å–∞–º–µ —Ç—Ä–µ–±–∞ –∑–Ω–∞–π—Ç–∏ –≤ –ø–∞–º'—è—Ç—ñ
- –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –∑–∞–≥–∞–ª—å–Ω—ñ –∑–Ω–∞–Ω–Ω—è, –¢–Ü–õ–¨–ö–ò —Ç–µ —â–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ

–¢–≤–æ—è –¥—É–º–∫–∞:"""
        else:
            # Include previous steps in prompt
            history = "\n".join([
                f"–ö—Ä–æ–∫ {i+1}:\n  –î—É–º–∫–∞: {step['thought']}\n  –î—ñ—è: {step['action']}\n  –†–µ–∑—É–ª—å—Ç–∞—Ç: {step['observation'][:100]}..."
                for i, step in enumerate(steps)
            ])

            thought_prompt = f"""üö´ TABULA RASA: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É. –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π pretrained knowledge.

–ü–æ–ø–µ—Ä–µ–¥–Ω—ñ –∫—Ä–æ–∫–∏:
{history}

–ü–æ—Ç–æ—á–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—â–æ —Ç–µ–±–µ –Ω–∞–≤—á–∏–ª–∏):
{context_text}

–ó–∞–≤–¥–∞–Ω–Ω—è: {task}

–ö—Ä–æ–∫ {iteration + 1}. –©–æ –¥–∞–ª—ñ? –ë–∞–∑—É–π—Å—è –¢–Ü–õ–¨–ö–ò –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –≤–∏—â–µ."""

        # Generate thought
        try:
            thought_response = await llm.generate_async(
                messages=[{"role": "user", "content": thought_prompt}],
                temperature=0.3,
                max_tokens=200
            )
            thought = thought_response.strip()
            logger.info(f"Thought: {thought}")
        except Exception as e:
            logger.error(f"Error generating thought: {e}")
            thought = "–ì–æ—Ç–æ–≤–∏–π –≤—ñ–¥–ø–æ–≤—ñ—Å—Ç–∏ –∑ –Ω–∞—è–≤–Ω–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"

        # Determine action
        thought_lower = thought.lower()

        if any(keyword in thought_lower for keyword in ["–≥–æ—Ç–æ–≤–∏–π", "–¥–æ—Å—Ç–∞—Ç–Ω—å–æ", "–º–æ–∂—É –≤—ñ–¥–ø–æ–≤—ñ—Å—Ç–∏", "answer", "ready"]):
            action = "answer"
            observation = "–ì–æ—Ç–æ–≤–æ –¥–æ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ"
            steps.append({
                "thought": thought,
                "action": action,
                "observation": observation
            })
            logger.info(f"Action: {action}")
            break

        elif any(keyword in thought_lower for keyword in ["—à—É–∫–∞—Ç–∏", "–∑–Ω–∞–π—Ç–∏", "–ø–æ—Ç—Ä—ñ–±–Ω–æ", "search", "find", "need"]):
            action = "search"

            # Extract search query from thought (for logging only)
            search_query = extract_search_query(thought)
            logger.info(f"Action: {action} - Query: {search_query}")

            # Use existing embedding to search Qdrant
            query_vector = state.get("message_embedding")
            if not query_vector:
                observation = "–ù–µ–º–∞—î embedding –¥–ª—è –ø–æ—à—É–∫—É"
                logger.warning(observation)
            else:
                try:
                    search_results = await qdrant.search_similar(
                        query_vector=query_vector,
                        top_k=3,
                        only_relevant=True,
                    )

                    # Map Qdrant results to simple structure
                    formatted_results = []
                    for hit in search_results:
                        payload = hit.get("payload") or {}
                        formatted_results.append({
                            "content": payload.get("fact") or "",
                            "score": hit.get("score", 0.0),
                            "source_msg_uid": payload.get("messageid") or payload.get("record_id") or "unknown",
                            "timestamp": payload.get("timestamp"),
                        })

                    # Append to context
                    retrieved_context.extend(formatted_results)
                    context_text = "\n".join([
                        f"[{i}] ({ctx['source_msg_uid']}): {ctx['content']}"
                        for i, ctx in enumerate(retrieved_context)
                    ])

                    observation = format_search_results(formatted_results)
                    logger.info(f"Observation: Found {len(formatted_results)} Qdrant results")

                except Exception as e:
                    logger.error(f"Error during search: {e}")
                    observation = f"–ü–æ–º–∏–ª–∫–∞ –ø–æ—à—É–∫—É: {e}"

            steps.append({
                "thought": thought,
                "action": action,
                "observation": observation
            })

        else:
            # Default: assume ready to answer
            action = "answer"
            observation = "–ü—Ä–∏—Å—Ç—É–ø–∞—é –¥–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ"
            steps.append({
                "thought": thought,
                "action": action,
                "observation": observation
            })
            logger.info(f"Action: {action} (default)")
            break

    logger.info(f"ReAct loop completed after {len(steps)} steps")

    return {
        "react_steps": steps
    }
